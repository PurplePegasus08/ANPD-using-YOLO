{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('/home/pegasus/Documents/NUMBERplates/best2.pt')\n",
    "\n",
    "# ✅ Correct training call\n",
    "model.train(\n",
    "    data='/home/pegasus/Documents/NUMBERplates/My First Project.v12i.yolov8W/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=5,\n",
    "    save=True,\n",
    "    name='retrained_model',\n",
    "    resume=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load trained YOLO model\n",
    "model = YOLO('/home/pegasus/Documents/NUMBERplates/best2.pt')\n",
    "\n",
    "# Directory containing test images\n",
    "image_folder = \"/home/pegasus/Documents/NUMBERplates/testimgs\"\n",
    "output_txt = \"ocr_results_simple.txt\"\n",
    "\n",
    "# Create output file\n",
    "with open(output_txt, \"w\") as f:\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        if not image_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "        # Run YOLO prediction\n",
    "        results = model.predict(image_path, imgsz=640, conf=0.3)\n",
    "\n",
    "        # Load original image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        for r in results:\n",
    "            for i, box in enumerate(r.boxes):\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                plate_img = img[y1:y2, x1:x2]\n",
    "\n",
    "                # Resize and basic grayscale conversion\n",
    "                plate_img = cv2.resize(plate_img, (400, 100))\n",
    "                gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Basic threshold to help Tesseract\n",
    "                _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                # Run Tesseract OCR\n",
    "                config = \"--psm 7\"\n",
    "                text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "\n",
    "                # Log results\n",
    "                f.write(f\"{image_file} - Plate {i+1}: {text}\\n\")\n",
    "                print(f\"{image_file} - Plate {i+1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load trained YOLO model\n",
    "model = YOLO('/home/pegasus/Documents/NUMBERplates/best2.pt')\n",
    "\n",
    "# Folder with input images\n",
    "image_folder = \"/home/pegasus/Documents/NUMBERplates/testimgs\"\n",
    "\n",
    "# Loop through all images\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if not image_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "    # Run YOLO prediction\n",
    "    results = model.predict(image_path, imgsz=640, conf=0.3)\n",
    "\n",
    "    # Load image with OpenCV, convert to RGB\n",
    "    cv_img = cv2.imread(image_path)\n",
    "    rgb_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to PIL image for drawing\n",
    "    pil_img = Image.fromarray(rgb_img)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    # Draw all detected bounding boxes\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], outline=\"red\", width=3)\n",
    "\n",
    "    # Show image with bounding boxes\n",
    "    pil_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving cropped images\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load trained YOLO model\n",
    "model = YOLO('/home/pegasus/Documents/NUMBERplates/best2.pt')\n",
    "\n",
    "# Input folder with test images\n",
    "image_folder = \"/home/pegasus/Documents/NUMBERplates/testimgs\"\n",
    "\n",
    "# Output folder for cropped number plates\n",
    "output_folder = \"/home/pegasus/Documents/NUMBERplates/cropped_plates\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over images\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if not image_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    results = model.predict(image_path, imgsz=640, conf=0.3)\n",
    "\n",
    "    # Load image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    for r_index, r in enumerate(results):\n",
    "        for i, box in enumerate(r.boxes):\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            cropped = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Save cropped plate image\n",
    "            cropped_filename = f\"{os.path.splitext(image_file)[0]}_plate{i+1}.jpg\"\n",
    "            cropped_path = os.path.join(output_folder, cropped_filename)\n",
    "            cv2.imwrite(cropped_path, cropped)\n",
    "\n",
    "print(f\"✅ Cropped plates saved to: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import os\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Path to your folder of plate images\n",
    "image_folder = '/home/pegasus/Documents/NUMBERplates/cropped_plates'\n",
    "output_txt_path = '/home/pegasus/Documents/NUMBERplates/ocr_results.txt'\n",
    "\n",
    "# Get image list\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Open the output file\n",
    "with open(output_txt_path, 'w', encoding='utf-8') as file:\n",
    "    # Iterate through each image and extract text\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        result = ocr.ocr(image_path, cls=True)\n",
    "\n",
    "        plate_text = []\n",
    "        if result and result[0]:\n",
    "            for line in result[0]:\n",
    "                plate_text.append(line[1][0])\n",
    "\n",
    "        # Join detected text into a single string\n",
    "        final_text = ' '.join(plate_text).strip()\n",
    "        final_output = final_text if final_text else 'No text detected'\n",
    "\n",
    "        # Print to console and write to file\n",
    "        print(f\"{image_name} -> {final_output}\")\n",
    "        file.write(f\"{image_name} -> {final_output}\\n\")\n",
    "\n",
    "print(f\"\\n✅ All OCR results saved to: {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_folder = '/home/pegasus/Documents/NUMBERplates/cropped_plates_for_ocr'  # Replace with your folder path\n",
    "output_txt = 'results.txt'\n",
    "\n",
    "# Initialize OCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Create/overwrite result file\n",
    "with open(output_txt, 'w') as f_out:\n",
    "    # List all images\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "\n",
    "        # Load and preprocess\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        contrast = clahe.apply(gray)\n",
    "\n",
    "        blur = cv2.GaussianBlur(contrast, (3, 3), 0)\n",
    "        _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Save temporary image for OCR\n",
    "        temp_path = 'temp_preprocessed.jpg'\n",
    "        cv2.imwrite(temp_path, thresh)\n",
    "\n",
    "        # OCR\n",
    "        result = ocr.ocr(temp_path, cls=True)\n",
    "        plate_text = []\n",
    "        if result and result[0]:\n",
    "            for line in result[0]:\n",
    "                plate_text.append(line[1][0])\n",
    "\n",
    "        final_text = ' '.join(plate_text) if plate_text else 'No text detected'\n",
    "        print(f\"{image_name} -> {final_text}\")\n",
    "\n",
    "        # Save to txt file\n",
    "        f_out.write(f\"{image_name} -> {final_text}\\n\")\n",
    "\n",
    "print(f\"\\n✅ All results saved to: {output_txt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------GUI\n",
    "import os\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, simpledialog, messagebox\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize OCR and YOLO model\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "model = YOLO(\"/home/pegasus/Documents/NUMBERplates/best2.pt\")\n",
    "\n",
    "# GUI to select multiple images and output filename\n",
    "def select_images():\n",
    "    return filedialog.askopenfilenames(title=\"Select Images\", filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "\n",
    "def get_output_filename():\n",
    "    return simpledialog.askstring(\"Output File\", \"Enter output text filename (e.g., result.txt):\")\n",
    "\n",
    "def process_images(image_paths, output_filename):\n",
    "    output_dir = \"results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_text_path = os.path.join(output_dir, output_filename)\n",
    "    all_results = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        cropped_texts = []\n",
    "        image_name = os.path.basename(image_path)\n",
    "        results = model.predict(image_path, imgsz=320, conf=0.2)\n",
    "        orig_img = cv2.imread(image_path)\n",
    "\n",
    "        for i, r in enumerate(results):\n",
    "            boxes = r.boxes.xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "            for j, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = box\n",
    "                crop = orig_img[y1:y2, x1:x2]\n",
    "\n",
    "                # Save cropped image\n",
    "                crop_name = f\"crop_{os.path.splitext(image_name)[0]}_{j}.jpg\"\n",
    "                crop_path = os.path.join(output_dir, crop_name)\n",
    "                cv2.imwrite(crop_path, crop)\n",
    "\n",
    "                # OCR\n",
    "                result = ocr.ocr(crop_path, cls=True)\n",
    "                plate_text = []\n",
    "\n",
    "                if result and result[0]:\n",
    "                    for line in result[0]:\n",
    "                        text = line[1][0]\n",
    "                        cleaned = ''.join(c for c in text if c.isalnum()).upper()\n",
    "                        plate_text.append(cleaned)\n",
    "                else:\n",
    "                    plate_text.append(\"NoText\")\n",
    "\n",
    "                plate_line = ' '.join(plate_text)\n",
    "                cropped_texts.append(plate_line)\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(orig_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Save annotated image\n",
    "        annotated_path = os.path.join(output_dir, f\"annotated_{image_name}\")\n",
    "        cv2.imwrite(annotated_path, orig_img)\n",
    "\n",
    "        # Collect all plate lines for this image\n",
    "        all_results.append(f\"{image_name} -> {' '.join(cropped_texts)}\")\n",
    "        print(f\"{image_name} Detected Plate: {' '.join(cropped_texts)}\")\n",
    "\n",
    "    # Save to output text file\n",
    "    with open(output_text_path, 'w') as f:\n",
    "        for line in all_results:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    messagebox.showinfo(\"Done\", f\"Processed {len(image_paths)} image(s).\\nText saved to {output_text_path}.\")\n",
    "\n",
    "# Main GUI window\n",
    "root = tk.Tk()\n",
    "root.withdraw()  \n",
    "\n",
    "# Run workflow\n",
    "images = select_images()\n",
    "if images:\n",
    "    output_name = get_output_filename()\n",
    "    if output_name:\n",
    "        process_images(images, output_name if output_name.endswith(\".txt\") else output_name + \".txt\")\n",
    "    else:\n",
    "        print(\"❌ Output filename not provided.\")\n",
    "else:\n",
    "    print(\"❌ No images selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
